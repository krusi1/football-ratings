{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def collect_ratings(soup, team):\n",
    "    if team == 'home':\n",
    "        i = 0\n",
    "    if team == 'away':\n",
    "        i = 1\n",
    "        \n",
    "    lineup    = soup.find_all('div', {'class': 'kick__data-grid__main'})[i].find_all('a')\n",
    "    subs      = soup.find_all('div', {'class': 'kick__data-grid__main'})[i+4].find_all('a')[0::2]\n",
    "    subs_time = soup.find_all('div', {'class': 'kick__data-grid__main'})[i+4].find_all('div', {'class': 'kick__substitutions__time'})[0::2]\n",
    "\n",
    "    ratings =  [parse_ratings(player) for player in lineup]\n",
    "    ratings.extend([parse_ratings(player, time) for player, time in zip(subs, subs_time)])\n",
    "    \n",
    "    return ratings\n",
    "\n",
    "def parse_ratings(player, time=0):\n",
    "    \n",
    "    name = player.get('href').split('/')[1]\n",
    "    \n",
    "    rating = player.get_text().strip()\n",
    "\n",
    "    if any(char.isdigit() for char in rating):\n",
    "        rating = rating[-3:]\n",
    "    else:\n",
    "        rating = ''\n",
    "    \n",
    "    if time == 0:\n",
    "        start = time\n",
    "    else: \n",
    "        start = int(time.get_text().replace(\"'\", \"\").split(' ')[0])\n",
    "    \n",
    "    return [name, rating, start]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find match links\n",
    "urls = dict()\n",
    "for year in range(2010, 2021):\n",
    "    \n",
    "    season = str(year) + '-' + str(year+1)[-2:]\n",
    "    \n",
    "    session = HTMLSession()\n",
    "    url = 'https://www.kicker.de/bundesliga/spieltag/' + season + '/-1'\n",
    "    resp = session.get(url)\n",
    "    soup = BeautifulSoup(resp.html.html, features='lxml')\n",
    "\n",
    "    fixture = soup.find_all('div', {'class': 'kick__v100-gameList__gameRow'})\n",
    "    urls[season] = [i.find_all('a', {'class': 'kick__v100-scoreBoard kick__v100-scoreBoard--standard'})[0].get('href').replace('analyse', 'schema') for i in fixture]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-11\n",
      "2011-12\n",
      "2012-13\n",
      "2013-14\n",
      "2014-15\n",
      "2015-16\n",
      "2016-17\n",
      "2017-18\n",
      "2018-19\n",
      "2019-20\n",
      "2020-21\n"
     ]
    }
   ],
   "source": [
    "### Get ratings\n",
    "\n",
    "df_all = pd.DataFrame()\n",
    "\n",
    "for season in urls.keys():\n",
    "    \n",
    "    print(season)\n",
    "\n",
    "    for url in urls[season]:\n",
    "\n",
    "        ### Scrape data\n",
    "\n",
    "        session = HTMLSession()\n",
    "        resp = session.get('https://www.kicker.de'+url)\n",
    "        soup = BeautifulSoup(resp.html.html, features='lxml')\n",
    "\n",
    "\n",
    "        ### Parse data\n",
    "\n",
    "        match_info = soup.find_all('div', {'class': 'kick__v100-scoreboardInfo'})[0].find_all('a')[0].get('href').replace('/spieltag', '')[1:].split('/')\n",
    "\n",
    "        scores = soup.find_all('div', {'class': 'kick__v100-scoreBoard__scoreHolder'})[0].get_text().replace('\\n', '').split(':')\n",
    "\n",
    "        teams = [i.get('href').split('/')[1] for i in soup.find_all('a', {'class': 'kick__v100-gameCell__team'})]\n",
    "\n",
    "        data = dict()\n",
    "        data['match_info']= {'competition': match_info[0],\n",
    "                             'season': match_info[1], \n",
    "                             'round': match_info[2]\n",
    "                            }\n",
    "        data['home'] = {'ratings': collect_ratings(soup, 'home'),\n",
    "                        'team': teams[0],\n",
    "                        'score': scores[0]\n",
    "                       }\n",
    "        data['away'] = {'ratings': collect_ratings(soup, 'away'),\n",
    "                        'team': teams[1],\n",
    "                        'score': scores[1]\n",
    "                       }\n",
    "\n",
    "\n",
    "\n",
    "        ### Create dataframe\n",
    "\n",
    "        for i in ['home', 'away']:\n",
    "            data[i]['df'] = pd.DataFrame(data[i]['ratings'], columns = ['player_name', 'rating', 'start'])\n",
    "            data[i]['df']['team'] = data[i]['team']\n",
    "            data[i]['df']['score'] = data[i]['score']\n",
    "            data[i]['df']['home'] = 1 if i == 'home' else 0\n",
    "\n",
    "        df_both = data['home']['df'].append(data['away']['df'], ignore_index=True)\n",
    "\n",
    "        for i in data['match_info'].keys():\n",
    "            df_both[i] = data['match_info'][i]\n",
    "            \n",
    "        df_both['season2'] = season\n",
    "\n",
    "        df_all = df_all.append(df_both, ignore_index=True)\n",
    "\n",
    "\n",
    "### Export data        \n",
    "df_all.to_csv('input/ratings_bundesliga.csv', index=False)\n",
    "df_all[['team']].rename(columns={'team': 'team_ratings'}).groupby('team_ratings').count().to_csv('input/team_names_ratings.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
